{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Playing with Metop  AVHRR data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary\n",
    "In this tutorial, we will read Metop AVHRR data and display a few composites, in satellite projection and on a couple of areas, and add coastlines to some images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Todo:\n",
    "- add areas.yaml to satpy, with germ area\n",
    "- change coastline directory\n",
    "- mention installation of pycoast and gshhs data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Finding the files, filtering with time\n",
    "The data for this tutorial is comprised of a handfull of Metop-B AVHRR/3 granules, that span over a couple of hours time. Since we just want work with a fraction of all that data, one solution is to define a start and end time and filter the files we provide to `Scene`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from satpy import Scene, find_files_and_readers\n",
    "from datetime import datetime\n",
    "import pprint\n",
    "\n",
    "files = find_files_and_readers(base_dir='/tcenas/scratch/pytroll/ex2',\n",
    "                               reader='avhrr_eps_l1b',\n",
    "                               start_time=datetime(2018, 10, 7 ,9, 25),\n",
    "                               end_time=datetime(2018, 10, 7 , 9, 30))\n",
    "\n",
    "#files=sorted(files)\n",
    "scn = Scene(filenames=files)\n",
    "pprint.pprint(files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we decide on a composite to load and display it on screen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(scn.available_composite_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "composite = 'overview'\n",
    "scn.load([composite])\n",
    "scn.show(composite)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resampling and displaying with coastlines\n",
    "Resampling is done exactly as in the previous tutorial. However this time we will display the data with coastlines on top."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newscn = scn.resample('euro1')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "newscn.show(composite, overlay={'coast_dir': '/tcenas/scratch/pytroll/shapes/', 'color': (255, 0, 0), 'resolution': 'i'})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For more information on which parameters you can pass for the coastline burning, check the pycoast documentation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dynamic area resampling\n",
    "For polar data, it can be convenient do resample the data in a given projection, but adapt the area extent to the actual data being resampled. For this, we have at the moment two dynamic areas we can use: `omerc_bb` for the oblique mercator projection and `laea_bb` for the lambert azimuthal equal-area projection. _Note_: `laea_bb` here will not yield a sensible result for the used dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resample and show the image\n",
    "newscn = scn.resample('omerc_bb')\n",
    "newscn.show(composite, overlay={'coast_dir': '/tcenas/scratch/pytroll/shapes/', 'color': (255, 0, 0), 'resolution': 'i'})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering the data by area\n",
    "When we have many data granules, it can be convenient to load only those covering a given area. We can achieve this by using the parameter filtering during the `Scene` instanciation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = find_files_and_readers(base_dir='/tcenas/scratch/pytroll/ex2',\n",
    "                               reader='avhrr_eps_l1b')\n",
    "scn = Scene(filenames=files, filter_parameters={'area':'germ'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "composite = 'natural_color'\n",
    "scn.load([composite])\n",
    "newscn = scn.resample('eurol')\n",
    "newscn.show(composite, overlay={'coast_dir': '/tcenas/scratch/pytroll/shapes/', 'color': (255, 0, 0), 'resolution': 'i'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2.1\n",
    "Generate an `ndvi` product using the individual channels and display the result on the `euron1` area. Then save your work as PNG.\n",
    "\n",
    "NDVI formula: ndvi = (vis08 - vis06) / (vis08 + vis06)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
